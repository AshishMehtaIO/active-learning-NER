{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "BHU2up3V1UU6",
    "outputId": "0967fd8d-67b3-4687-9522-6166629366af"
   },
   "outputs": [],
   "source": [
    "!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "x8TaSlPS1bOh",
    "outputId": "449eb30d-d2a7-463e-fbfb-59ea2107d86c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\ashis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import conll2002\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier, RidgeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn_crfsuite\n",
    "import sklearn_crfsuite.metrics\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import nltk\n",
    "from nltk.classify import MaxentClassifier\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('conll2002')\n",
    "\n",
    "regex = re.compile(\n",
    "        r'^(?:http|ftp)s?://'  # http:// or https://\n",
    "        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\\.)+(?:[A-Z]{2,6}\\.?|[A-Z0-9-]{2,}\\.?)|'  # domain...\n",
    "        r'localhost|'  # localhost...\n",
    "        r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})'  # ...or ip\n",
    "        r'(?::\\d+)?'  # optional port\n",
    "        r'(?:/?|[/?]\\S+)$', re.IGNORECASE)\n",
    "\n",
    "def wordshape(text):\n",
    "\n",
    "    t1 = re.sub('[A-Z]', 'X',text)\n",
    "    t2 = re.sub('[a-z]', 'x', t1)\n",
    "    return re.sub('[0-9]', 'd', t2)\n",
    "\n",
    "def getfeats(word, o):\n",
    "    \"\"\" This takes the word in question and\n",
    "    the offset with respect to the instance\n",
    "    word \"\"\"\n",
    "    features = [\n",
    "        (str(o) + 'word', word)\n",
    "        # TODO: add more features here.\n",
    "    ]\n",
    "    return features\n",
    "\n",
    "def gettag(tag, o):\n",
    "    features = [ (str(o) +\"tag\", tag) ]\n",
    "    return features\n",
    "\n",
    "def gethyphen(word, o):\n",
    "    if('-' in word):\n",
    "        features = [(str(o) +\"hyphen\", 1)]\n",
    "    else:\n",
    "        features = [(str(o) +\"hyphen\", 0)]\n",
    "    return features\n",
    "    \n",
    "def capletter(word, o):\n",
    "    if(word[0].isupper):\n",
    "        features = [(str(o) +\"first_upper\", 1)]\n",
    "    else:\n",
    "        features = [(str(o) +\"first_upper\", 0)]\n",
    "    return features\n",
    "\n",
    "def noun_suffix(word, o):\n",
    "    if(word.endswith('o') or word.endswith('or') or word.endswith('a') or word.endswith('ora')):\n",
    "        features = [(str(o) +\"common_suffix\", 1)]\n",
    "    else:\n",
    "        features = [(str(o) +\"common_suffix\", 0)]\n",
    "    return features\n",
    "\n",
    "def get_wordshape(word, o):\n",
    "    feature = [(str(o) +\"word_shape\", wordshape(word))]\n",
    "    return feature\n",
    "\n",
    "def all_upper(word, o):\n",
    "    if(word.isupper()):\n",
    "        return [(str(o) +\"all_upper\", 1)]\n",
    "    else:\n",
    "        return [(str(o) +\"all_upper\", 0)]\n",
    "\n",
    "def all_lower(word, o):\n",
    "    if(word.islower()):\n",
    "        return [(str(o) +\"all_lower\", 1)]\n",
    "    else:\n",
    "        return [(str(o) +\"all_lower\", 0)]\n",
    "\n",
    "def has_apostrophe(word, o):\n",
    "    if(\"'\" in word):\n",
    "        return [(str(o) +\"apostrophe\", 1)]\n",
    "    else:\n",
    "        return [(str(o) +\"apostrophe\", 0)]\n",
    "\n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def special_characters(word, o):\n",
    "    if(isEnglish(word)):\n",
    "        return [(str(o) +\"special_characters\", 0)]\n",
    "    else:\n",
    "        return [(str(o) +\"special_characters\", 1)]\n",
    "\n",
    "def onlynum(word, o):\n",
    "    if(word.isdigit()):\n",
    "        return [(str(o) +\"onlynum\", 1)]\n",
    "    else:\n",
    "        return [(str(o) +\"onlynum\", 0)]\n",
    "\n",
    "def contains_num(word, o):\n",
    "    if(any(char.isdigit() for char in word)):\n",
    "        return [(str(o) +\"contains_num\", 1)]\n",
    "    else:\n",
    "        return [(str(o) +\"contains_num\", 0)]\n",
    "\n",
    "def ending_fullstop(word, o):\n",
    "    if(word[-1] == '.'):\n",
    "        return [(str(o) +\"fullstop\", 1)]\n",
    "    else:\n",
    "        return [(str(o) +\"fullstop\", 0)]\n",
    "\n",
    "def minlen(word, o):\n",
    "    if(len(word)>=2):\n",
    "        return [(str(o) +\"minlen\", 1)]\n",
    "    else:\n",
    "        return [(str(o) +\"minlen\", 0)]\n",
    "\n",
    "def punctuation(word, o):\n",
    "    for i in word: \n",
    "      if i in string.punctuation: \n",
    "        return [(str(o) +\"punctuation\", 1)]\n",
    "    return [(str(o) +\"punctuation\", 0)]\n",
    "\n",
    "def all_punctuation(word, o):\n",
    "    count = 0\n",
    "    for i in word: \n",
    "      if i in string.punctuation: \n",
    "        count = count +1\n",
    "    if(count == len(word)):\n",
    "        return [(str(o) +\"punctuation\", 1)]\n",
    "    else:\n",
    "        return [(str(o) +\"punctuation\", 0)]\n",
    "\n",
    "def is_stopword(word, o):\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    if(word in stop_words):\n",
    "        return([(str(o) +\"is_stop\", 1)])\n",
    "    else:\n",
    "        return([(str(o) +\"is_stop\", 0)])\n",
    "\n",
    "\n",
    "def isRomanNumeral(word, o):\n",
    "    numeral = word.upper()\n",
    "    validRomanNumerals = [\"M\", \"D\", \"C\", \"L\", \"X\", \"V\", \"I\"]\n",
    "    for letters in numeral:\n",
    "        if letters not in validRomanNumerals:\n",
    "            return ([(str(o) +\"is_roman\", 0)])\n",
    "\n",
    "    return ([(str(o) + \"is_roman\", 1)])\n",
    "\n",
    "\n",
    "def contains_dots(word, o):\n",
    "    if word.find('.')==-1:\n",
    "        return ([(str(o) + \"has_dot\", 0)])\n",
    "\n",
    "    return ([(str(o) + \"has_dot\", 1)])\n",
    "\n",
    "\n",
    "def single_char(word, o):\n",
    "    if len(word)==1:\n",
    "        return ([(str(o) + \"is_char\", 1)])\n",
    "\n",
    "    return ([(str(o) + \"is_char\", 0)])\n",
    "\n",
    "def is_url(word, o):\n",
    "    if re.match(regex, word) is not None:\n",
    "        return ([(str(o) + \"is_url\", 1)])\n",
    "    return ([(str(o) + \"is_url\", 0)])\n",
    "\n",
    "\n",
    "def word2features(sent, i):\n",
    "    \"\"\" The function generates all features\n",
    "    for the word at position i in the\n",
    "    sentence.\"\"\"\n",
    "    features = []\n",
    "    # the window around the token\n",
    "    for o in [-4,-3, -2,-1,0,1,2, 3, 4]:\n",
    "        if i+o >= 0 and i+o < len(sent):\n",
    "            word = sent[i+o][0]\n",
    "            tag = sent[i+o][1]\n",
    "            featlist = getfeats(word, o)\n",
    "            features.extend(featlist)\n",
    "            featlist = gettag(tag, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = gethyphen(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = capletter(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = noun_suffix(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = get_wordshape(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = all_upper(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = all_lower(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = has_apostrophe(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = special_characters(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = onlynum(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = contains_num(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = ending_fullstop(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = isRomanNumeral(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = contains_dots(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = single_char(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "            featlist = is_url(word, o)\n",
    "            features.extend(featlist)\n",
    "\n",
    "    \n",
    "    word = sent[i][0]\n",
    "    tag = sent[i][1]\n",
    "\n",
    "    features.extend([(\"word_lower\", word.lower())])\n",
    "\n",
    "    features.extend([(\"word_len\", len(word))])\n",
    "\n",
    "    if (i == 0):\n",
    "        features.extend([(\"firstword\", 1)])\n",
    "    else:\n",
    "        features.extend([(\"firstword\", 0)])\n",
    "\n",
    "    features.extend([(\"bias\", 1)])\n",
    "    \n",
    "    return dict(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucnQ_s6k8S4y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cbmP69XL-Khv",
    "outputId": "109ba715-6d10-41aa-d8f5-5bf9e14ac0df"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rj-1nnfV1cpb"
   },
   "outputs": [],
   "source": [
    "train = ConllCorpusReader('./CoNLL-2003', 'eng.train', ['words', 'pos', 'ignore', 'chunk'])\n",
    "dev = ConllCorpusReader('./CoNLL-2003', 'eng.testa', ['words', 'pos', 'ignore', 'chunk'])\n",
    "test = ConllCorpusReader('./CoNLL-2003', 'eng.testb', ['words', 'pos', 'ignore', 'chunk'])\n",
    "\n",
    "train_sents = list(train.iob_sents())\n",
    "dev_sents = list(dev.iob_sents())\n",
    "test_sents = list(test.iob_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents = list(conll2002.iob_sents('esp.train'))\n",
    "dev_sents = list(conll2002.iob_sents('esp.testa'))\n",
    "test_sents = list(conll2002.iob_sents('esp.testb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V8LTHv_SUuZt",
    "outputId": "373bec0d-efc2-4937-ed7b-96c0ae5e9ffb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14987"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWr73Tzu1e3C"
   },
   "outputs": [],
   "source": [
    "unannotated_dataset = list(train.iob_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mrvafjm_1i-F"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "train_labels = []\n",
    "\n",
    "for sent in unannotated_dataset:\n",
    "    unannotated_dataset_feats = []\n",
    "    unannotated_dataset_labels = []\n",
    "\n",
    "    for i in range(len(sent)):\n",
    "        feats = word2features(sent, i)   \n",
    "        unannotated_dataset_feats.append(feats)\n",
    "        unannotated_dataset_labels.append(sent[i][-1])\n",
    "\n",
    "    X_train.append(unannotated_dataset_feats)\n",
    "    train_labels.append(unannotated_dataset_labels)\n",
    "\n",
    "ind_select=np.array([len(y)>0 for y in X_train])\n",
    "X_train = np.array(X_train)[ind_select]\n",
    "train_labels = np.array(train_labels)[ind_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXzVK3UuEzmI"
   },
   "outputs": [],
   "source": [
    "test_feats = []\n",
    "test_labels = []\n",
    "\n",
    "# for sent in test_sents:\n",
    "#     for i in range(len(sent)):\n",
    "#         feats = word2features(sent, i)\n",
    "#         test_feats.append(feats)\n",
    "#         test_labels.append(sent[i][-1])\n",
    "\n",
    "\n",
    "for sent in test_sents:\n",
    "    test_sents_feats = []\n",
    "    test_sents_labels = []\n",
    "\n",
    "    for i in range(len(sent)):\n",
    "        feats = word2features(sent, i)   \n",
    "        test_sents_feats.append(feats)\n",
    "        test_sents_labels.append(sent[i][-1])\n",
    "\n",
    "    test_feats.append(test_sents_feats)\n",
    "    test_labels.append(test_sents_labels)\n",
    "\n",
    "ind_select=np.array([len(y)>0 for y in test_feats])\n",
    "test_feats = np.array(test_feats)[ind_select]\n",
    "test_labels = np.array(test_labels)[ind_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Jki8KCS2Cvi"
   },
   "outputs": [],
   "source": [
    "initial_size_of_training_set = 20\n",
    "\n",
    "training_dataset_feats = {}\n",
    "training_dataset_labels = {}\n",
    "\n",
    "all_length=np.array([len(X_train[i]) for i in range(len(X_train))])\n",
    "\n",
    "indices=all_length.argsort()[-initial_size_of_training_set:][::-1]\n",
    "\n",
    "\n",
    "training_dataset_feats = list(X_train[indices])\n",
    "training_dataset_labels =  list(train_labels[indices])\n",
    "\n",
    "X_train = np.delete(X_train, indices)\n",
    "train_labels = np.delete(train_labels, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "njVJWUarWNmP"
   },
   "outputs": [],
   "source": [
    "X_train_random=X_train.copy()\n",
    "train_labels_random=train_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHPDjAujV-TP"
   },
   "outputs": [],
   "source": [
    "initial_training_dataset_feats=training_dataset_feats.copy()\n",
    "initial_training_dataset_labels=training_dataset_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dGqU5R4d28xy",
    "outputId": "ba5ccc1c-591e-4e67-a08b-ef7e0266f5e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14021,), (14021,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-40w38RAk-X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j3nzy5kXbWkP"
   },
   "outputs": [],
   "source": [
    "\n",
    "# X_train = X_train[0:10000]\n",
    "# train_labels = train_labels[0:10000]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zq9I9Gd69E-T"
   },
   "outputs": [],
   "source": [
    "# prediction_of_classifier[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJA0CxzR7KA2"
   },
   "outputs": [],
   "source": [
    "# crf.predict_marginals_single(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iYY0wzA3AGZ4",
    "outputId": "26f56aa9-6ca2-4768-f948-76cb6d389621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE OF TRAINING DATASET  20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels_predicted_for_unannotated_data = []\n",
    "\n",
    "print(\"SIZE OF TRAINING DATASET \",len(training_dataset_feats))\n",
    "crf.fit(training_dataset_feats,training_dataset_labels)\n",
    "prediction_of_classifier=crf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AU6enffjB3tV"
   },
   "outputs": [],
   "source": [
    "# def get_uncertainy_of_predicted_values(X_train,crf,prediction_of_classifier,n):\n",
    "#     uncertainity_value_all_predictions=[]\n",
    "#     for sent in range(len(X_train)):\n",
    "#         uncertainity_value=0\n",
    "#         li=[]\n",
    "#         for words in range(len(X_train[sent])):\n",
    "#             li.append(crf.predict_marginals_single(X_train[sent])[words][prediction_of_classifier[sent][words]])\n",
    "#         li=np.array(li)\n",
    "#         ind=li.argsort()[:n]\n",
    "\n",
    "        \n",
    "#         uncertainity_value=sum(1-li[ind])/(len(X_train[sent])+0.0005)\n",
    "#         uncertainity_value_all_predictions.append(uncertainity_value)\n",
    "#     return uncertainity_value_all_predictions\n",
    "\n",
    "\n",
    "def get_uncertainy_of_predicted_values(X_train,crf):\n",
    "\n",
    "    uncertainity_value_all_predictions=[]\n",
    "    for sent in range(len(X_train)):\n",
    "        uncertainity_value=0\n",
    "        kk=crf.predict_marginals_single(X_train[sent])\n",
    "        uncertainity_value=sum([1-max(kk[i].values()) for i in range(len(X_train[sent]))])        \n",
    "        uncertainity_value=uncertainity_value/(len(X_train[sent]))\n",
    "        uncertainity_value_all_predictions.append(uncertainity_value)\n",
    "\n",
    "    return uncertainity_value_all_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_token_entropy(X_train,crf):\n",
    "\n",
    "    entropy_value_all_predictions=[]\n",
    "    for sent in range(len(X_train)):\n",
    "        sentence_entropy_value=0.0\n",
    "        kk=crf.predict_marginals_single(X_train[sent])\n",
    "        for i in range(len(X_train[sent])):\n",
    "            probs = np.array(list(kk[i].values()))\n",
    "            entropy = -np.sum(probs*np.log2(probs))\n",
    "            sentence_entropy_value += entropy\n",
    "            \n",
    "        entropy_value_all_predictions.append(sentence_entropy_value)\n",
    "\n",
    "    return entropy_value_all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZyyKZGSDiwg"
   },
   "outputs": [],
   "source": [
    "# sent=1\n",
    "# kk=crf.predict_marginals_single(X_train[sent])\n",
    "# # 1-max(kk[0].values())\n",
    "\n",
    "# sum([1-max(kk[0].values()) for i in range(len(X_train[sent]))])\n",
    "\n",
    "# [1-max(kk[i].values()) for i in range(len(X_train[sent]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2pgZEWAFd8N"
   },
   "outputs": [],
   "source": [
    "# sent=1\n",
    "# uncertainity_value=0\n",
    "# for words in range(len(X_train[sent])):\n",
    "#     print((1-crf.predict_marginals_single(X_train[sent])[words][prediction_of_classifier[sent][words]]))\n",
    "#     uncertainity_value=uncertainity_value+(1-crf.predict_marginals_single(X_train[sent])[words][prediction_of_classifier[sent][words]])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dmPMSpUkHgXk"
   },
   "outputs": [],
   "source": [
    "# len(training_dataset_feats),len(training_dataset_labels)\n",
    "# m=np.array([1,3,2])\n",
    "# np.argsort(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PAr0yyHMA7D-",
    "outputId": "4c5bc939-e032-423f-eca8-8fcf0215a5c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14001,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  40 f1 score  0.33212546227274825\n",
      "(13981,)\n",
      "n =  60 f1 score  0.34891562966302736\n",
      "(13961,)\n",
      "n =  80 f1 score  0.3647360200053499\n",
      "(13941,)\n",
      "n =  100 f1 score  0.36844708207770566\n",
      "(13921,)\n",
      "n =  120 f1 score  0.3665870839901266\n",
      "(13901,)\n",
      "n =  140 f1 score  0.377536789804784\n",
      "(13881,)\n",
      "n =  160 f1 score  0.3888288726702243\n",
      "(13861,)\n",
      "n =  180 f1 score  0.39568001383346846\n",
      "(13841,)\n",
      "n =  200 f1 score  0.39504397119494217\n",
      "(13821,)\n",
      "n =  220 f1 score  0.40493060437170214\n",
      "(13801,)\n",
      "n =  240 f1 score  0.41020205392584375\n",
      "(13781,)\n",
      "n =  260 f1 score  0.40958412707056197\n",
      "(13761,)\n",
      "n =  280 f1 score  0.41765819662404896\n",
      "(13741,)\n",
      "n =  300 f1 score  0.4092804945758661\n",
      "(13721,)\n",
      "n =  320 f1 score  0.4087347717238471\n",
      "(13701,)\n",
      "n =  340 f1 score  0.42212165830079507\n",
      "(13681,)\n",
      "n =  360 f1 score  0.42285407509345935\n",
      "(13661,)\n",
      "n =  380 f1 score  0.4275370398393788\n",
      "(13641,)\n",
      "n =  400 f1 score  0.42614713563326273\n",
      "(13621,)\n",
      "n =  420 f1 score  0.4342959546320808\n",
      "(13601,)\n",
      "n =  440 f1 score  0.43325245271519264\n",
      "(13581,)\n",
      "n =  460 f1 score  0.44282580211036154\n",
      "(13561,)\n",
      "n =  480 f1 score  0.4494907516005645\n",
      "(13541,)\n",
      "n =  500 f1 score  0.4501669246602067\n",
      "(13521,)\n",
      "n =  520 f1 score  0.45259095477287914\n",
      "(13501,)\n",
      "n =  540 f1 score  0.45515721085105976\n",
      "(13481,)\n",
      "n =  560 f1 score  0.4592333561611444\n",
      "(13461,)\n",
      "n =  580 f1 score  0.4588330173183618\n",
      "(13441,)\n",
      "n =  600 f1 score  0.4635288646244155\n",
      "(13421,)\n",
      "n =  620 f1 score  0.46125249240192\n",
      "(13401,)\n",
      "n =  640 f1 score  0.4610868900507506\n",
      "(13381,)\n",
      "n =  660 f1 score  0.46360328392225725\n",
      "(13361,)\n",
      "n =  680 f1 score  0.46352870793863155\n",
      "(13341,)\n",
      "n =  700 f1 score  0.46700828400940314\n",
      "(13321,)\n",
      "n =  720 f1 score  0.46790882921721355\n",
      "(13301,)\n",
      "n =  740 f1 score  0.47024572877963144\n",
      "(13281,)\n",
      "n =  760 f1 score  0.4706863696079609\n",
      "(13261,)\n",
      "n =  780 f1 score  0.46643434189693633\n",
      "(13241,)\n",
      "n =  800 f1 score  0.47001304426287716\n",
      "(13221,)\n",
      "n =  820 f1 score  0.4712054411806842\n",
      "(13201,)\n",
      "n =  840 f1 score  0.47229551110826223\n",
      "(13181,)\n",
      "n =  860 f1 score  0.4966575427894248\n",
      "(13161,)\n",
      "n =  880 f1 score  0.4731724067907258\n",
      "(13141,)\n",
      "n =  900 f1 score  0.49788422960856993\n",
      "(13121,)\n",
      "n =  920 f1 score  0.4759649952634567\n",
      "(13101,)\n",
      "n =  940 f1 score  0.47690047763174476\n",
      "(13081,)\n",
      "n =  960 f1 score  0.4772640916080664\n",
      "(13061,)\n",
      "n =  980 f1 score  0.48075318875783885\n",
      "(13041,)\n",
      "n =  1000 f1 score  0.4788818402213849\n",
      "(13021,)\n",
      "n =  1020 f1 score  0.48135840643411365\n",
      "(13001,)\n",
      "n =  1040 f1 score  0.4822083621572146\n",
      "(12981,)\n",
      "n =  1060 f1 score  0.48122939469946135\n",
      "(12961,)\n",
      "n =  1080 f1 score  0.4840517272821442\n",
      "(12941,)\n",
      "n =  1100 f1 score  0.4850755634308245\n",
      "(12921,)\n",
      "n =  1120 f1 score  0.4844844372284721\n",
      "(12901,)\n",
      "n =  1140 f1 score  0.48283367076849865\n",
      "(12881,)\n",
      "n =  1160 f1 score  0.48106973288552296\n",
      "(12861,)\n",
      "n =  1180 f1 score  0.482492549290422\n",
      "(12841,)\n",
      "n =  1200 f1 score  0.4857059353177371\n",
      "(12821,)\n",
      "n =  1220 f1 score  0.4896797572869419\n",
      "(12801,)\n",
      "n =  1240 f1 score  0.4917583900969648\n",
      "(12781,)\n",
      "n =  1260 f1 score  0.49232228187504945\n",
      "(12761,)\n",
      "n =  1280 f1 score  0.49690789897888743\n",
      "(12741,)\n",
      "n =  1300 f1 score  0.49636577881295774\n",
      "(12721,)\n",
      "n =  1320 f1 score  0.4980718325527046\n",
      "(12701,)\n",
      "n =  1340 f1 score  0.4992835835553542\n",
      "(12681,)\n",
      "n =  1360 f1 score  0.4964296839201779\n",
      "(12661,)\n",
      "n =  1380 f1 score  0.4984047148481528\n",
      "(12641,)\n",
      "n =  1400 f1 score  0.49898572754284204\n",
      "(12621,)\n",
      "n =  1420 f1 score  0.5010988897585529\n",
      "(12601,)\n",
      "n =  1440 f1 score  0.4997220972169252\n",
      "(12581,)\n",
      "n =  1460 f1 score  0.5015985950790356\n",
      "(12561,)\n",
      "n =  1480 f1 score  0.5021693548969848\n",
      "(12541,)\n",
      "n =  1500 f1 score  0.5006199267838456\n",
      "(12521,)\n",
      "n =  1520 f1 score  0.5025873087927458\n",
      "(12501,)\n",
      "n =  1540 f1 score  0.5019360358996827\n",
      "(12481,)\n",
      "n =  1560 f1 score  0.5025484099175633\n",
      "(12461,)\n",
      "n =  1580 f1 score  0.501986736142549\n",
      "(12441,)\n",
      "n =  1600 f1 score  0.5043146077820976\n",
      "(12421,)\n",
      "n =  1620 f1 score  0.5039547280626967\n",
      "(12401,)\n",
      "n =  1640 f1 score  0.5043317108984846\n",
      "(12381,)\n",
      "n =  1660 f1 score  0.508294606471757\n",
      "(12361,)\n",
      "n =  1680 f1 score  0.5084127549185168\n",
      "(12341,)\n",
      "n =  1700 f1 score  0.5072547543506611\n",
      "(12321,)\n",
      "n =  1720 f1 score  0.5090577619980873\n",
      "(12301,)\n",
      "n =  1740 f1 score  0.5062352719219311\n",
      "(12281,)\n",
      "n =  1760 f1 score  0.507857818421297\n",
      "(12261,)\n",
      "n =  1780 f1 score  0.5069791864608775\n",
      "(12241,)\n",
      "n =  1800 f1 score  0.509119159506666\n",
      "(12221,)\n",
      "n =  1820 f1 score  0.5083567517569599\n",
      "(12201,)\n",
      "n =  1840 f1 score  0.5097731458237098\n",
      "(12181,)\n",
      "n =  1860 f1 score  0.5088770699652134\n",
      "(12161,)\n",
      "n =  1880 f1 score  0.5085451503859602\n",
      "(12141,)\n",
      "n =  1900 f1 score  0.5087591500485704\n",
      "(12121,)\n",
      "n =  1920 f1 score  0.5127108422632044\n",
      "(12101,)\n",
      "n =  1940 f1 score  0.5095788032972584\n",
      "(12081,)\n",
      "n =  1960 f1 score  0.5141388767599808\n",
      "(12061,)\n",
      "n =  1980 f1 score  0.5122737705476845\n",
      "(12041,)\n",
      "n =  2000 f1 score  0.513588662549239\n",
      "(12021,)\n",
      "n =  2020 f1 score  0.5131618499849672\n",
      "(12001,)\n",
      "n =  2040 f1 score  0.5118139160057764\n",
      "(11981,)\n",
      "n =  2060 f1 score  0.5150998689035489\n",
      "(11961,)\n",
      "n =  2080 f1 score  0.5101067782515093\n",
      "(11941,)\n",
      "n =  2100 f1 score  0.5161795114270427\n",
      "(11921,)\n",
      "n =  2120 f1 score  0.5146660831461903\n",
      "(11901,)\n",
      "n =  2140 f1 score  0.5160356746079336\n",
      "(11881,)\n",
      "n =  2160 f1 score  0.5164252053528228\n",
      "(11861,)\n",
      "n =  2180 f1 score  0.5166224779167479\n",
      "(11841,)\n",
      "n =  2200 f1 score  0.517291408956647\n",
      "(11821,)\n",
      "n =  2220 f1 score  0.517883457680617\n",
      "(11801,)\n",
      "n =  2240 f1 score  0.517293673076912\n",
      "(11781,)\n",
      "n =  2260 f1 score  0.518593539169505\n",
      "(11761,)\n",
      "n =  2280 f1 score  0.5191234267401863\n",
      "(11741,)\n",
      "n =  2300 f1 score  0.5181051548788104\n",
      "(11721,)\n",
      "n =  2320 f1 score  0.5179812566870039\n",
      "(11701,)\n",
      "n =  2340 f1 score  0.519550696599497\n",
      "(11681,)\n",
      "n =  2360 f1 score  0.5191369193418441\n",
      "(11661,)\n",
      "n =  2380 f1 score  0.5180299084621499\n",
      "(11641,)\n",
      "n =  2400 f1 score  0.5188343331988474\n",
      "(11621,)\n",
      "n =  2420 f1 score  0.5207586151424323\n",
      "(11421,)\n",
      "n =  2620 f1 score  0.5268283421862302\n",
      "(11221,)\n",
      "n =  2820 f1 score  0.5276926051120843\n",
      "(11021,)\n",
      "n =  3020 f1 score  0.5299730524154949\n",
      "(10821,)\n",
      "n =  3220 f1 score  0.5310734814431993\n",
      "(10621,)\n",
      "n =  3420 f1 score  0.5324880943900705\n",
      "(10421,)\n",
      "n =  3620 f1 score  0.5339398119684907\n",
      "(10221,)\n",
      "n =  3820 f1 score  0.5339132800896217\n",
      "(10021,)\n",
      "n =  4020 f1 score  0.5345445872340283\n",
      "(9821,)\n",
      "n =  4220 f1 score  0.5329017137184626\n",
      "(9621,)\n",
      "n =  4420 f1 score  0.5353616756071531\n",
      "(9421,)\n",
      "n =  4620 f1 score  0.535345673100524\n",
      "(9221,)\n",
      "n =  4820 f1 score  0.5364125208711555\n",
      "(9021,)\n",
      "n =  5020 f1 score  0.5371241168214309\n",
      "(8821,)\n",
      "n =  5220 f1 score  0.537505142976749\n",
      "(8621,)\n",
      "n =  5420 f1 score  0.534652149223863\n",
      "(8421,)\n",
      "n =  5620 f1 score  0.5364609581578544\n",
      "(8221,)\n",
      "n =  5820 f1 score  0.5359927366285581\n",
      "(8021,)\n",
      "n =  6020 f1 score  0.5357165702905652\n",
      "(7821,)\n",
      "n =  6220 f1 score  0.5362762280649643\n",
      "(7621,)\n",
      "n =  6420 f1 score  0.5358293374817349\n",
      "(7421,)\n",
      "n =  6620 f1 score  0.53496230287736\n",
      "(7221,)\n",
      "n =  6820 f1 score  0.5345368322972172\n",
      "(7021,)\n",
      "n =  7020 f1 score  0.5346233942502736\n",
      "(6821,)\n",
      "n =  7220 f1 score  0.5365452532564019\n",
      "(6621,)\n",
      "n =  7420 f1 score  0.5347741437928687\n",
      "(6421,)\n",
      "n =  7620 f1 score  0.5359372622119067\n",
      "(6221,)\n",
      "n =  7820 f1 score  0.5346585911214627\n",
      "(6021,)\n",
      "n =  8020 f1 score  0.53442188643571\n",
      "(5821,)\n",
      "n =  8220 f1 score  0.5342914279997367\n",
      "(5621,)\n",
      "n =  8420 f1 score  0.5346190968768918\n",
      "(5421,)\n",
      "n =  8620 f1 score  0.5345931529887763\n",
      "(5221,)\n",
      "n =  8820 f1 score  0.5355902674358048\n",
      "(5021,)\n",
      "n =  9020 f1 score  0.5348773655748669\n",
      "(4821,)\n",
      "n =  9220 f1 score  0.5348754120682553\n",
      "(4621,)\n",
      "n =  9420 f1 score  0.5354961905951352\n",
      "(4421,)\n",
      "n =  9620 f1 score  0.5350009011668873\n",
      "(4221,)\n",
      "n =  9820 f1 score  0.5344923830187713\n",
      "(4021,)\n",
      "n =  10020 f1 score  0.5353301200138812\n",
      "(3821,)\n",
      "n =  10220 f1 score  0.5349599043022099\n",
      "(3621,)\n",
      "n =  10420 f1 score  0.5338507057511602\n",
      "(3421,)\n",
      "n =  10620 f1 score  0.533044625349873\n",
      "(3221,)\n",
      "n =  10820 f1 score  0.535027192937132\n",
      "(3021,)\n",
      "n =  11020 f1 score  0.5343225976005872\n",
      "(2821,)\n",
      "n =  11220 f1 score  0.5337056395956247\n",
      "(2621,)\n",
      "n =  11420 f1 score  0.5345950344728314\n",
      "(2421,)\n",
      "n =  11620 f1 score  0.5349537756656184\n",
      "(2221,)\n",
      "n =  11820 f1 score  0.5349850037497588\n",
      "(2021,)\n",
      "n =  12020 f1 score  0.5354790768556397\n",
      "(1821,)\n",
      "n =  12220 f1 score  0.5353200911807959\n",
      "(1621,)\n",
      "n =  12420 f1 score  0.5350100641095853\n",
      "(1421,)\n",
      "n =  12620 f1 score  0.5347755531306567\n",
      "(1221,)\n",
      "n =  12820 f1 score  0.5363455885460122\n",
      "(1021,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  13020 f1 score  0.5350534597559294\n",
      "(821,)\n",
      "n =  13220 f1 score  0.5352553109042844\n",
      "(621,)\n",
      "n =  13420 f1 score  0.5338731757438673\n",
      "(421,)\n",
      "n =  13620 f1 score  0.5346450077833734\n",
      "(221,)\n",
      "n =  13820 f1 score  0.533958143666812\n",
      "(21,)\n",
      "n =  14020 f1 score  0.5352919415461503\n",
      "(0,)\n",
      "n =  14041 f1 score  0.5348902888102199\n"
     ]
    }
   ],
   "source": [
    "i=3\n",
    "n=12\n",
    "iter_count=0\n",
    "sub_sample=20\n",
    "F_SCORE_TEST=[]\n",
    "NUMBER_OF_DATA=[]\n",
    "while(len(X_train)):\n",
    "    if iter_count>=120:\n",
    "        sub_sample=200\n",
    "\n",
    "    uncertainity_value_all_predictions=get_total_token_entropy(X_train,crf)\n",
    "    indices_of_most_confused_sentences = np.argsort(uncertainity_value_all_predictions)[-sub_sample:]\n",
    "    training_dataset_feats.extend(X_train[indices_of_most_confused_sentences])\n",
    "    training_dataset_labels.extend(train_labels[indices_of_most_confused_sentences])\n",
    "\n",
    "    X_train = np.delete(X_train, indices_of_most_confused_sentences)\n",
    "    train_labels = np.delete(train_labels, indices_of_most_confused_sentences)\n",
    "    print(X_train.shape)\n",
    "    crf.fit(training_dataset_feats,training_dataset_labels)\n",
    "    prediction_of_classifier=crf.predict(X_train)  \n",
    "\n",
    "    test_pred = crf.predict(test_feats)\n",
    "    NUMBER_OF_DATA.append(len(training_dataset_feats))\n",
    "    fscore_value=sklearn_crfsuite.metrics.flat_f1_score(test_labels, test_pred, average=\"macro\")\n",
    "    F_SCORE_TEST.append(fscore_value)\n",
    "    print(\"n = \",NUMBER_OF_DATA[-1],\"f1 score \",fscore_value)\n",
    "    \n",
    "    with open(\"TTE_eng.txt\", \"a\") as f:\n",
    "        f.write(str(NUMBER_OF_DATA[-1]) + \" \" + str(fscore_value)+\"\\n\")\n",
    "\n",
    "    i=i+1\n",
    "    iter_count=iter_count+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCIhjB6yRFEg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jP24bwafWLW6"
   },
   "source": [
    "#### RANDOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqfvpVXZWOB7"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train_random_s = X_train_random.copy()\n",
    "train_labels_random_s = train_labels_random.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWufrRv_VznX"
   },
   "outputs": [],
   "source": [
    "initial_size_of_training_set = 20\n",
    "\n",
    "# training_dataset_feats = {}\n",
    "# training_dataset_labels = {}\n",
    "\n",
    "# indices=np.random.randint(0, X_train_random_s.shape[0], size=initial_size_of_training_set)\n",
    "# training_dataset_feats = list(X_train_random_s[indices])\n",
    "# training_dataset_labels =  list(train_labels_random_s[indices])\n",
    "\n",
    "training_dataset_feats=initial_training_dataset_feats.copy()\n",
    "training_dataset_labels=initial_training_dataset_labels.copy()\n",
    "\n",
    "X_train = X_train_random_s\n",
    "train_labels = train_labels_random_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dDNC2vJcVzoM",
    "outputId": "770f27fe-f826-44dd-b48c-6bef20e4f8d4"
   },
   "outputs": [],
   "source": [
    "len(training_dataset_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3Yh32PdVzoU"
   },
   "outputs": [],
   "source": [
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s4xdHp8iVzoi"
   },
   "outputs": [],
   "source": [
    "# prediction_of_classifier[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRdyGm8qVzoy"
   },
   "outputs": [],
   "source": [
    "# crf.predict_marginals_single(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c9rzpeg3VzpE",
    "outputId": "5a65430b-f791-475d-8a04-9ca202ee598b"
   },
   "outputs": [],
   "source": [
    "\n",
    "labels_predicted_for_unannotated_data = []\n",
    "\n",
    "print(\"SIZE OF TRAINING DATASET \",len(training_dataset_feats))\n",
    "crf.fit(training_dataset_feats,training_dataset_labels)\n",
    "prediction_of_classifier=crf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yUIxbg4KVzpd",
    "outputId": "14981dd8-597b-43e0-8414-61cd885be32d"
   },
   "outputs": [],
   "source": [
    "len(training_dataset_feats),len(training_dataset_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TLv5vPQYeO8x",
    "outputId": "a47d14c6-f07f-48f9-efa9-1e0ad779a240"
   },
   "outputs": [],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ZpnoYo9LVzpk",
    "outputId": "ccc52134-9f0d-4e38-efcb-9236ae9c97a7"
   },
   "outputs": [],
   "source": [
    "i=3\n",
    "F_SCORE_TEST_RANDOM=[]\n",
    "NUMBER_OF_DATA_RANDOM=[]\n",
    "sub_sample=20\n",
    "iter_count=0\n",
    "while(len(X_train)):\n",
    "    if iter_count>=120:\n",
    "        sub_sample=200\n",
    "    ind_random=np.random.randint(0,len(X_train), size=sub_sample)\n",
    "\n",
    "  \n",
    "    training_dataset_feats.extend(X_train[ind_random])\n",
    "    training_dataset_labels.extend(train_labels[ind_random])\n",
    "\n",
    "    X_train = np.delete(X_train, ind_random)\n",
    "    train_labels = np.delete(train_labels, ind_random)\n",
    "    print(X_train.shape)\n",
    "\n",
    "    crf.fit(training_dataset_feats,training_dataset_labels)\n",
    "    # prediction_of_classifier=crf.predict(X_train)  \n",
    "\n",
    "    test_pred = crf.predict(test_feats)\n",
    "    NUMBER_OF_DATA_RANDOM.append(len(training_dataset_feats))\n",
    "    fscore_value=sklearn_crfsuite.metrics.flat_f1_score(test_labels, test_pred, average=\"macro\")\n",
    "    F_SCORE_TEST_RANDOM.append(fscore_value)\n",
    "    print(\"n = \",NUMBER_OF_DATA_RANDOM[-1],\"f1 score \",fscore_value)\n",
    "    \n",
    "    with open(\"TTE_english.txt\", \"a\") as f:\n",
    "        f.write(str(len(training_dataset_feats[0])) + \" \" + str(fscore_value)+\"\\n\")\n",
    "\n",
    "\n",
    "    i=i+1\n",
    "    iter_count=iter_count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTipfa5r2Eco"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "flZiDWnfrE7b",
    "outputId": "fea227c6-17b1-4ebb-8ea6-112c5715f275"
   },
   "outputs": [],
   "source": [
    "plt.plot(NUMBER_OF_DATA_RANDOM,F_SCORE_TEST_RANDOM,label='Random')\n",
    "plt.plot(NUMBER_OF_DATA,F_SCORE_TEST,label='Uncertainity Sampling') \n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXukyDyrXdws"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "uncertainity_sampling_LC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
